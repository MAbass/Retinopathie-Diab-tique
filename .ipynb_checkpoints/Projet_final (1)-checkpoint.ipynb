{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Projet final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeBNFm0gQS6V"
      },
      "source": [
        "# Projet final : Fashion Mnist Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9COb2q0KQS6a"
      },
      "source": [
        "![](https://images.unsplash.com/photo-1512436991641-6745cdb1723f?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
        "\n",
        "Photo by [Lauren Fleischmann](https://unsplash.com/photos/R2aodqJn3b8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj3IKT5TQS6b"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_6ZRAEQS6b"
      },
      "source": [
        "# Chargement des donnees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2KLeuxGOQS6c"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdCfv3FVQS6c"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3ONg15cQS6c"
      },
      "source": [
        "# Exploration des donnees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4CnyHvTqQS6d"
      },
      "source": [
        "# Explore the data, display some input images\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray_r')\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()\n",
        "# TODO Ajoouter plus d'exploration pour mieux connaitre les donnees : vous pouvez ajouter autant de celllules que vous voulez"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPkwHVxFQS6e"
      },
      "source": [
        "# Normalisation et encodage des labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o5iGbdlQS6e"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# TODO expliquer ce que fait la ligne suivante et pourquoi est-ce que c'est utile par rapport au modele cree en bas\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255.\n",
        "#TODO Normaliser le jeu de test et expliquer pourquoi est-ce important de faire la normalistion\n",
        "\n",
        "# TODO expliquer ce que fait les deux prochaines lignes et pourquoi est-ce que c'est utile par rapport au modele cree en bas\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], np.prod(X_train_norm.shape[1:]))\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], np.prod(X_test_norm.shape[1:]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHkpi937QS6f"
      },
      "source": [
        "# Creation de la fonction qui cree le modele"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gH1H02GQS6f"
      },
      "source": [
        "# Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # TODO : Aojoutez la première couche denses de 100 neurones avec la dimension d'entrée et relu comme fonction d'activation\n",
        "\n",
        "    model.add(Dense(10, activation='sigmoid'))\n",
        "\n",
        "    # TODO Ajouter la derniere couche avec le bon nombre de neurones et la bonne fonction d'activation, justifiez votre choix en commentaires\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEQcHTAZQS6f"
      },
      "source": [
        "# Creation, compilation et entrainement du model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5gqodgquQS6f"
      },
      "source": [
        "# TODO: Appeler la fonction my_model avec les bons parametres pour creer le modele\n",
        "model = \n",
        "\n",
        "# TODO mettre la bonne valeur pour le parametre loss de la methode compile et justifiez votre choix par rapport aux alternatifs\n",
        "model.compile(optimizer='adam', loss=, metrics=['accuracy'])\n",
        "\n",
        "# TODO mettre les valeurs pour le nombre d'epochs et de batch size en justifiant vos choix\n",
        "model.fit(X_train_norm, y_train_cat, epochs=, batch_size=)\n",
        "# TODO Expliquer ce que fait le modele fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFaTXYuEQS6g"
      },
      "source": [
        "# Evaluation du modele"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkTRyT4TQS6g"
      },
      "source": [
        "# Compute the accuracy of your model\n",
        "\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat)[1])\n",
        "# TODO : Evaluer le  model sur le jeu de test et expliquer la difference avec le jeu de train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVFKnwD1rM13"
      },
      "source": [
        "#TODO : Afin d'ameliorer les resultats ci-dessus, optimisez les hyperprametres suivants : nombre d'epochs et optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQe5Qr89QS6h"
      },
      "source": [
        "---"
      ]
    }
  ]
}